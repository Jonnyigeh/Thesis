\documentclass{subfiles}
\begin{document}
\subsection{Hartree-Fock}
As mentioned in the theory section\ref{sec:HF_theory}, the Hartree-Fock method is an iterative method to obtain optimal basis functions (single particle orbitals) that would minimize the energy, and by the variational method, converge towards the true ground state energy. This is inherently an approximaton, where we imagine that the electrons occupy the lowest possible single-particle orbitals, and it has been proven many times that this is a rather accurate approximation for many systems. \textcolor{red}{(Cite some sources here)}.
We will now outline the method without much information, before diving into each step in more detail and provide insights into the computational aspects of the method.
\begin{itemize}
    \item Construct an initial guess for the single-particle orbitals, $\{\phi_i\}$, often using atomic orbitals or other basis sets.
    \item Diagonalize the Fock matrix to obtain a new set of orbitals, $\{\phi_i\}$, and calculate Hartree-Fock energy, $E_{HF}$.
    \item Repeat the process until the energy converges, i.e. the change in energy between iterations is below a certain threshold.
    \item Calculate the total energy of the system, and the electron density, and use this to calculate other properties of the system.
\end{itemize}
The first step in the Hartree-Fock procedure is to define an initial ansatz for the trial wavefunction, which is typically represented as a Slater determinant, as discussed earlier. This ansatz requires an initial choice of basis set, which plays a crucial role in the overall success of the method. The initial basis set serves as a starting point for constructing orbitals and significantly influences the convergence of the self-consistent field (SCF) procedure.\\  
\\ Choosing an appropriate basis set is a nuanced and complex task. A well-chosen basis can simplify numerical calculations and accelerate convergence, whereas a poor choice may lead to slow convergence or even failure to converge. 



There are a multitude of basis sets to choose from, and the choice is guided by the nature of the system. For instance, in quantum dots systems with strong confinement, the quantum harmonic oscillator basis sets are often used to great success\cite{Yuan_2017}. A different procedure to using pre-defined basis sets, is to solve the Schr√∂dinger equation for the non-interacting system, and use these single-particle orbitals as the initial basis set. The latter may often yield quicker convergence due to the functions being specifically tailored for the potential, but at the cost of more computational resources, and in some cases may not even be possible. 
\\
\\ With the initial basis, we construct the Fock matrix, which is a matrix representation of the Fock operator in the basis of the single-particle orbitals. The Fock matrix is given by
\begin{align*}
    F_{pq} = h_{pq} + \sum_{i}^N u_{piqi}
\end{align*}
\textcolor{red}{not finished}
\subsection{Bipartite Hartree}
As presented in section \ref{sec:bipartite_H}, the Hartree method is also a self-consistent field method, where we solve the coupled eigenvalue equations for the two subsystems (particles) iteratively. The method is very similar to the Hartree-Fock method, and the main difference is that we do not include an exchange term and the wavefunction itself a single hartree product state. The general method is as follows:
\begin{itemize}
    \item Construct an initial guess for the single-particle orbitals, $\{\chi_i\}$.
    \item Diagonalize the Hartree matrix to obtain a new set of orbitals, $\{\chi_i\}$, and calculate the energy.
    \item Repeat the process until the energy converges, i.e. the change in energy between iterations is below a certain threshold.
    \item Calculate the total energy of the system, and the electron density, and use this to calculate other properties of the system.
end{itemize}
The way we solve this SCF procedure is by constructing the Hartree matrix, which is a matrix representation of the Hartree operator in the basis of the single-particle orbitals. The Hartree matrix is given in eq. \ref{eq:bipartite_hartree}, with an initial choice for the Hartree matrix as \emph{only} the single-body hamiltonians, i.e 
\begin{align*}
    f_{\alpha\beta}^(M0) = h_{\alpha\beta}^M
\end{align*}
which will be our initial starting point for our iterative process. 

\subsection{Study of indistinguishability}
One of the core features of our system - and the foundation of our qubit design -is that the two particles confined in our potential trap act as \emph{distinguishable} particles. As we are looking to trap electrons, indistinguishable particles, we are dealing with fermions, and the Pauli exclusion principle states clearly that two fermions cannot occupy the same quantum state. This fundamental principle would normally prevnt us from constructing product states, as the quantum state of any fermionic system must be anti-symmetric under particle exchange.
\\ However, we are assuming that the potential trap is constructed such that there are minimal correlations between the two particles, and that the wavefunction can be approximated as a product state. In this analysis we shall look at how "distinguishable" our system actually is, and find a distance between wells where we can safely assume the particles to be distinguishable. \\ \\
To make an assessment of the systems distinguishability we will firstly look at the eigen-energies of the system given that we either:
\begin{itemize}
    \item Assume the particles to be distinguishable: \\ We construct the wavefunction as a product state,
    \begin{align*}
        \Psi(\mathbf{r}_1, \mathbf{r}_2) = \phi_L(\mathbf{r}_1)\otimes\phi_R(\mathbf{r}_2)
    \end{align*} 
    where $\phi_L$ and $\phi_R$ are the single-particle functions located in the left and right well respectivley. We then calculat the energy by diagonalizing the Hamiltonian matrix for this product state system. In such a product state system the Hamiltonian matrix becomes
    \begin{align*}
        H = H_L \otimes I + I \otimes H_R + V
    \end{align*}
    where $H_L$ and $H_R$ are the single-particle Hamiltonians for the left and right well, and $V$ is the interaction term between the two particles.
    \item Assume the particles to be indistinguishable, and construct a Slater determinant that we solve using Hartree-Fock theory.
\end{itemize}


If we are successful, we should find that for a certain distance between the wells, the "true" distinguishable energy will overlap with the indistinguishable HF-energy. Should this be the case, we can safely assume that the particles behave as distinguishable particles for our intents and purposes. 


\subsection{Optimization of the potential parameters}
As our goal is to realize single-qubit gates and the two-qubit iSwap gate, we need to find suitable configurations of our potential where we achieve the desired degeneracy in energy levels and also our desired level of entanglement between the two particles. As we've discussed in earlier sections the two configurations we are looking for are:
\begin{itemize}
    \item Config I: The measurement configuration, where all energy levels are distinct and there are minimal correlations between the two subsystems (particles). This corresponds to keeping all Von Neumann entropies in our system as close to zero as possible. With this, we know that our two-body energy eigenstates will have a product state structure, and maximal overlap with the Hartree product states $\ket{00}, \ket{01}, \ket{10}, \ket{11}$.
    \item Config II: The entangled configuration, where we have a degeneracy in the energy levels of our system. This degeneracy will give rise to an avoided crossings in the energy spectrum for the first and second energy eigenstates. In this configuration, the 1st and 2nd energy eigenstates are maximally entangled, while the other energy eigenstates are kept as pure as possible (product states). This corresponds to an entropy equal to 1 for $\ket{\phi_1}$ and $\ket{\phi_2}$, and 0 for $\ket{\phi_0}$ and $\ket{\phi_4}$. 
\end{itemize}
As an initial search, we make a grid search over the potential parameters, mostly to map out the landscape of the potential and find regions where we expect to find the desired configuations. Our grid search will be over the following parameters:
\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        Parameter & Range & Description \\
        \hline
        $D_l, D_r$ & [$D_{\text{min}}$, $D_{\text{max}}$] & The depth of the potential well \\
        $k_l, k_r$ & [$k_{\text{min}}$, $k_{\text{max}}$] & The width of the potential well \\
        $d$ & [$d_{\text{min}}$, $d_{\text{max}}$] & The distance between the two potential wells \\
        \hline
    \end{tabular}
    \caption{The parameters we will search over in our grid search}
\end{table}
with the constraint that $2 * D / \sqrt(k) < l$ where $l$ are the number of basis functions allocated to each well, as we've discussed earlier. This is to ensure that the basis functions are well within the potential well, and that we do not have any basis functions that are cut off by the potential. This then becomes a \emph{constrained optimization problem}. To perform our optimization we will use the \texttt{scipy.optimize} package, and the \texttt{minimize} function. We will use the \texttt{COBYQA} method, which is a derivative-free optimization method that is well suited for constrained optimization problems. This method is built on the concept of \emph{sequential quadratic programming}, that solves constrained, non-linear problems. For more details on the method, see \cite{razh_cobyqa}. The optimization will be done as follows:
\begin{itemize}
    \item Randomize an initial configuration of the parameters within the specified ranges.
    \item Run the optimization algorithm, with a high tolerance for convergence.
    \item Log 'good' regions where we achive the desired configurations.
    \item Initialize new configurations using the 'good' parameters found from the grid search.
    \item Run the optimization algorithm again, with a lower tolerance for convergenece.
\end{itemize}
\end{document}