\documentclass{subfiles}
\begin{document}
%% GENERAL STUDY OF MORSE DOUBLE WELL
\section{General study of the system}
In this secton we will outline the methods used to study our system in general. These studies will be used to set up our system in such a way that our desired configurations are achieved, whilst also ensuring that the system is stable, well-defined and physically meaningful. To this end there are a few things we need to consider:
\begin{itemize}
    \item At what well separation is our approximation of the two particles being distinguishable valid (to a certain degree)?
    \item What parameters do we need to set in order to achieve our desired configurations I and II?
    \item Will our choice of basis functions be sufficient to descibe our system?
    \item How do we ensure that our system is stable, and well-defined—while also physically meaningful?
\end{itemize}
%% Distinguishability of the particles
\subsection{Assessing validity of product state approximation}\label{sec:distinguishability} %% Should we instead call 'Asses validity of product state approximation'?
One of the core featues of our qubit design is that each electron is tightly confined in its own well of the Morse double-well potential, so that their spatial wavefunctions have minimal overlap. Strictly speaking, electrons are indistinguishable fermions and their total two-particle wavefunction must be anti-symmetric under particle exchange to adhere to the Pauli exclusion principle \cite{berera2021quantum, griffiths2018introduction}. However, when the spatial overlap between localized orbitals $\braket{\phi_L|\phi_R}$  becomes vanishingly small (for large separations $d$ and/or very deep, narrow wells), the exchange integral tends to zero. In that limit, the anti-symmetric wavefunction
\begin{align*}
    \Psi_A(x_1, x_2) = \frac{1}{\sqrt{2}} \bigg[\phi_L(x_1)\phi_R(x_2) - \phi_L(x_2)\phi_R(x_1)\bigg]
\end{align*}
reduces to a simple product state $\phi_L(x_1)\phi_R(x_2)$, and the electrons behave as effectively \emph{distinguishable} particles. 

In this analysis we aim to quantify the degree of distinguishability between the two particles in our system, and determine the conditions under which we can treat them as distinguishable and identify the inter-well separation limit where our product state approach is valid. Concretely, for each inter-well separation $d$, we compute
\begin{itemize}
    \item \textbf{The product state energy:}
    We form the separable product state wavefunction
    \begin{align*}
        \Psi(x_1, x_2) = \phi_L(x_1)\phi_R(x_2),
    \end{align*}
    and assemble the Hamiltonian matrix for this product state system $H$ = $H_L\otimes I + I \otimes H_R + V_{LR}$, where $H_L$ and $H_R$ are the single-particle Hamiltonians for the left and right wells, respectively, and $V_{LR}$ is the inter-well coupling potential. We diagonalize this Hamiltonian to obtain the product state energy $E_{prod}(d)$.
    \item \textbf{The anti-symmetric (CI) energy:}
    We construct the anti-symmetric wavefunction $\Psi_A$ as a sum of product state and solve the full two-body Configuration Interaction (Section \ref{sec:CI_method}) to find $E_{anti}(d)$. 
\end{itemize}
We then examine the energy difference between the two states to quantify the exchange interaction
\begin{align*}
    \Delta E(d) = E_{anti}(d) - E_{prod}(d).
\end{align*}
which should tend to zero as the inter-well separation $d$ increases, indicating that the exchange interaction becomes negligible and the particles can be treated as distinguishable. The distance $d^*$ at which $\Delta E(d^*) \approx 0$ defines the regime where the product-state treatment becomes fully justified.


%% Optimization of the potential parameters
\subsection{Parameter optimization}\label{sec:optimization_procedure}
As our goal is to realize single-qubit gates and the two-qubit iSwap gate, we need to find suitable configurations of our potential where we achieve the desired degeneracy in energy levels and also our desired level of entanglement between the two particles. As we have discussed in earlier sections the two configurations we are looking for are:
\begin{itemize}
    \item \textbf{Config I}: The measurement configuration, where all energy levels are distinct and there are minimal correlations between the two subsystems (particles). This corresponds to keeping all Von Neumann entropies in our system as close to zero as possible. With this, we know that our two-body energy eigenstates will have a product state structure, and maximal overlap with the Hartree product states $\ket{00}, \ket{01}, \ket{10}, \ket{11}$.
    \item \textbf{Config II}: The entangled configuration, where we have a degeneracy in the energy levels of our system. This degeneracy will give rise to an avoided crossings in the energy spectrum for the first and second energy eigenstates. In this configuration, the 1st and 2nd energy eigenstates are maximally entangled, while the other energy eigenstates are kept as pure as possible (product states). This corresponds to an entropy equal to 1 for $\ket{\phi_1}$ and $\ket{\phi_2}$, and 0 for $\ket{\phi_0}$ and $\ket{\phi_4}$. 
\end{itemize}
As an initial search, we make a grid search over the potential parameters, mostly to map out the landscape of the potential and find regions where we expect to find the desired configuations. Our grid search will be over the parameters presented in table \ref{tab:parameter_search}, 
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        Parameter & Range & Description \\
        \hline
        $D_l, D_r$ & [$D_{\text{min}}$, $D_{\text{max}}$] & The depth of the potential well \\
        $k_l, k_r$ & [$k_{\text{min}}$, $k_{\text{max}}$] & The width of the potential well \\
        $d$ & [$d_{\text{min}}$, $d_{\text{max}}$] & The distance between the two potential wells \\
        \hline
    \end{tabular}
    \caption{The parameters we will search over in our grid search}
    \label{tab:parameter_search}
\end{table}
with the constraint that $2D / \sqrt{k} < l$ where $l$ are the number of basis functions allocated to each well, as we have discussed earlier. This is to ensure that the basis functions are well within the potential well, and that we do not have any basis functions that are cut off by the potential. This then becomes a \emph{constrained optimization problem}. To perform our optimization we will use the \texttt{scipy.optimize} package, and the \texttt{minimize} function. We will use the \texttt{COBYQA} method, which is a derivative-free optimization method that is well suited for constrained optimization problems. This method is built on the concept of \emph{sequential quadratic programming}, that solves constrained, non-linear problems. For more details on the method, see \cite{razh_cobyqa}. The optimization procedure is outlined in \ref{alg:parameter_optimization}:
\begin{algorithm}[h!]
\caption{Parameter optimization procedure: High-level overview}
\textbf{Input: }{Parameter ranges \(\mathcal{R}\), \(\epsilon_{\text{coarse}}\), \(\epsilon_{\text{fine}}\)}
\,\,\,\,\textbf{Output: }{Final refined parameter sets}

\textbf{1. Initialization}\\
Generate a collection of random parameter configurations within \(\mathcal{R}\).

\textbf{2. Coarse Optimization}\\
For each configuration in the collection:
\begin{itemize}
  \item Run the optimizer with convergence tolerance \(\epsilon_{\text{coarse}}\).
  \item If the optimized result meets the desired criteria, retain it as a candidate.
\end{itemize}

\textbf{3. Fine Optimization}\\
For each candidate parameter set:
\begin{itemize}
  \item Re-run the optimizer with tighter tolerance \(\epsilon_{\text{fine}}\).
  \item Add the refined output to the final results.
\end{itemize}

\textbf{4. Return} the final set of optimized parameters.
\label{alg:parameter_optimization}
\end{algorithm}

\subsubsection{Objective function}
An objective function is constructed for the optimizer, which is the object to be minimized by our optimization algorithm. We will have two separate objective functions, one for each configuration we are looking for. Across both configurations, we want to minimize the $\zeta$-parameter, which directly controls the stability of time-evolution through the Hamiltonian matrix. The parameters is defined as 
\begin{equation}
    \zeta = E_4 - E_1 - E_2 + E_0,\label{eq:zeta}
\end{equation}
and we can identify this as the \emph{accumulated phase} of the rotated time-evolution operator $U = e^{-iHt}$, expressed in terms of the energy eigenstates, $U = \sum_i^4 e^{-iE_it}\ket{\phi_i}\bra{\phi_i}$. We see that written in matrix form in the logical state basis $\{\ket{ij}\}$, this propagator is (where $\ket{11}$ is the 4th energy eigenstate)
\begin{align*}
    U = \begin{pmatrix}
        e^{-iE_{00}t} & 0 & 0 & 0 \\
        0 & e^{-iE_{01}t} & 0 & 0 \\
        0 & 0 & e^{-iE_{10}t} & 0 \\
        0 & 0 & 0 & e^{-iE_{11}t}
    \end{pmatrix}.
\end{align*}
The energy eigenstates themselves are not unique, because we are free to apply arbitrary single-qubit phase rotations to shift their individual phases without affecting populations (as they are cancelled in any innerproduct). By performing local Z-rotations on qubit A and B, we can absorb the phases on the first three states ($\ket{00}$, $\ket{10}$, $\ket{01}$) into $\ket{11}$. In other words, invoking a single global phase, we use single-qubit rotations on each qubit to collect the relative phases onto $\ket{11}$. After the rotations, the condition
\begin{align*}
    E_{11} = E_{10} + E_{01} - E_{00}
\end{align*}
means that the excitation energy from the 0th state $\ket{00}\to\ket{11}$ equals the sum of excitations $\ket{00}\to\ket{10}$ and $\ket{00}\to\ket{01}$, which aids in ensuring phase stability in our iSwap-like two-qubit gate operation \cite{ku2020suppression}. 
\\

Configuration I, as we have mentioned, should have all energy levels distinct. This introduces penalties in our objective function corresponding to the overlap between energy eigenvalues and we want to Von Neumann entropies to be as close to zero as possible. In python we realise this in the following way
\begin{lstlisting}[language=Python]
target_entropy = np.zeros(4)
detuning_penalty = -min(0.5, np.abs(e_L - e_R))
entropy_penalty = np.linalg.norm(entropy - target_entropy)
ZZ_penalty = np.abs(E_4 - E_1 - E_2 + E_0)
\end{lstlisting}
where \texttt{e\_L} and \texttt{e\_R} are the energy levels of the left and right well, and \texttt{entropy} is the Von Neumann entropy of the subsystems. The \texttt{detuning\_penalty} is a penalty that is introduced to ensure that the energy levels are distinct, and the \texttt{entropy\_penalty} is a penalty that ensures that the entropy is as close to zero as possible. The objective function is then the sum of these two penalties. Furthermore, we would like the two configurations parameters to be close in parameter space, so that our evolution between the two configurations is smoooth. We introduce a penalty for this as well, similar to the \texttt{entropy\_penalty}. We also want to penalize off-diagonal coupling terms in the Hamiltonian matrix, as these will introduce unwanted couplings between the subsystems in our measurement configuration. This is done by introducing a \texttt{off\_diagonal\_penalty} that is the scaled sum of the absolute values of the off-diagonal elements in the Hamiltonian matrix.

In configuration II we have a similar detuning penalty, but in this configuration we do want degeneracy in the 1st Hartree energy level in each well, as well as having an entropy penalty, but with a different target vector. We also here want to penalize certain off-diagonal coupling terms in the Hamiltonian matrix that induces unwanted transitions during evolution, and reward the correct coupling between the subsystems that induce entanglement between the first two excited energy eigenstates. This coupling is closely related to the energy difference between said energy states, so we want to minimize $\Delta E_{12} / J_{12}$, where $J_{12}$ is the coupling strength between the first two energy eigenstates through the \texttt{J\_deltaE\_penalty}. 
The objective function is then again the sum of these penalties.
\begin{lstlisting}[language=Python]
target_entropy = np.array([0, 1, 1, 0])
detuning_penalty = np.abs(e_L - e_R)
entropy_penalty = np.linalg.norm(entropy - target_entropy)
ZZ_penalty = np.abs(E_4 - E_1 - E_2 + E_0)
J_12 = np.abs(H[1, 2])  
deltaE_12 = np.abs(E_2 - E_1)  
J_deltaE_penalty = - np.abs(J_12 / deltaE_12 + 1e-12)  
\end{lstlisting}

%%% DVR basis
\subsection{Sinc-Discrete Variable Representation}\label{sec:sinc_dvr_validation}
We implement the Sinc-Discrete Variable Representation (Sinc-DVR) basis in Python to discretize our one-dimensional quantum problem on a uniform grid. Sinc-DVRs delta-like basis functions render the kinetic operator analytic and collapse multi-dimensional integrals (Section \ref{sec:basis_set}), making it both efficient and accurate for smooth, localized potentials. Its effectiveness depends however, on the ability to accurately represent the relevant physical states of the system at hand.  \\

As a test case, we consider a single particle trapped in a Morse potential\eqref{eq:morse_potential}, which models an anharmonic bounded oscillator potential with well-known analytical and numerical solutions. A brief reminder, the Morse potential is given by
\begin{align*}
    V(x) = D \left(1 - e^{-a(x - x_0)}\right)^2,
\end{align*}
where $D$ is the depth of the potential well, $a$ is the width of the potential, and $x_0$ is the equilibrium position of the potential. This potential is well-suited for benchmarking, as it is smooth and localised, and also well represents the more complex double-well potential we are later interested in. The exact eigenstates and eigenvalues are computed analytically, using the expressions in \eqref{eq:morse_eigenstates} and \eqref{eq:morse_eigenvalues}, which are derived from the Schrödinger equation for the Morse potential
The procedure to compute, and compare, the energy spectrum and eigenstates of the Morse potential using the Sinc-DVR basis and the exact energy eigenstates is as follows:
\begin{itemize}
    \item Set up the potential using a set of parameters $D$, $a$, and $x_0$.
    \item Construct the Sinc-DVR basis functions $\phi_n(x)$ over a uniform grid of points $x_i$.
    \item Construct the Hamiltonian matrix $H$ using analytical expressions for Sinc-DVR.
    \item Diagonalize the Hamiltonian matrix to obtain the energy eigenvalues and eigenstates.
    \item Compute overlaps $S_{nm}$ and energy deviations $\Delta E_n$ between the Sinc-DVR and exact eigenstates.
\end{itemize}
This procedure allows us to validate the Sinc-DVR basis by comparing the computed energy eigenvalues and eigenstates with the exact solutions of the Morse potential. We aim for high accuracy in the lowest lying energy eigenstates and energy levels, as these are the most relevant for our quantum control protocols. In the following sections, we will outline the numerical implementation of these steps.
\subsubsection*{Energy spectrum} 
In the following code snippet, we highlight some of the key steps in the construction of the quantum mechanical system and the diagonalization of the Hamiltonian matrix, which is used to obtain the energy eigenstates and eigenvalues of the system. 
\begin{lstlisting}[language=Python, label=lst:dvr_validation]
N = 200
x = np.linspace(-1, 2, N)
dx = x[1] - x[0]
def morse_function(x, n, lmbda, x_e, c):
    def normalization(n, lmbda, c):
        return (
            (scipy.special.factorial(n) * (2 * lmbda - 2 * n - 1) * c /
             scipy.special.gamma(2 * lmbda - n))**0.5 # Gamma(n+1) = factorial(n)
        )
    z = 2 * lmbda * np.exp(-c * (x - x_e))
    return (
            normalization(n, lmbda, c) *
             z**(lmbda - n - 0.5) * np.exp(-z / 2) * 
                scipy.special.genlaguerre(n, 2 * lmbda - 2 * n - 1)(z)
    )
def compute_eigenenergies(c, D, l):
    hnu = 2 * c * np.sqrt(D / 2)
    E_n = np.zeros(l)
    for n in range(l):
        E_n[n] = hnu * (n + 0.5) - (c * hnu * (n + 0.5)**2) / np.sqrt(8 * D)

    return E_n

def morse_potential(x, D, a, x0):
    
    return D * (1 - np.exp(-a * (x - x0)))**2 - D

V_matrix = np.diag(morse_potential(x, D, a, x0))
T_dvr = np.zeros((N, N))
for i in range(N):
    for j in range(N):
        if i == j:
            T_dvr[i, j] = np.pi**2 / (6 * dx**2)
        else:
            T_dvr[i, j] = ((-1)**(i - j)) / (dx**2 * (i - j)**2)

H_dvr = T_dvr + V_matrix
# Diagonalize the Hamiltonian
E_dvr, psi_dvr = np.linalg.eigh(H_dvr)
E_exact = compute_eigenenergies(c, D, N)
psi_exact = morse_function(x, np.arange(N), lmbda, 0, c)
\end{lstlisting}
To then actually assess the performance of the Sinc-DVRs ability to reproduce the energy eigenvalues, we compute the absolute deviance
\begin{align*}
    \Delta E_n = |E_n^{\text{DVR}} - E_n^{\text{exact}}|,
\end{align*}
where $E_n^{\text{DVR}}$ is the $n$th energy eigenvalue computed using the Sinc-DVR basis, and $E_n^{\text{exact}}$ is the exact energy eigenvalue of the system. The goal is to show that the Sinc-DVR basis can reproduce the relevant energy levels of the system with high accuracy.
\subsubsection*{Energy eigenstates}
To compare the energy eigenstates of the two basis sets, we compute the overlap between the Sinc-DVR basis functions and the exact energy eigenstates of the system. The overlap is defined as
\begin{align*}
    S_{nm} = \braket{\phi_n|\psi_m} = \int_{-\infty}^{\infty} \phi_n(x) \psi_m(x) dx,
\end{align*}
where $\phi_n(x)$ is the Sinc-DVR basis function and $\psi_m(x)$ is the exact energy eigenstate of the system. The overlap can be computed numerically using a direct Riemann sum,
\begin{align*}
    \int_a^b f(x) dx \approx \sum_{i=0}^{N-1} f(x_i) \Delta x, 
\end{align*} 
as shown in the following code snippet, building on the previous code snippet \ref{lst:dvr_validation}:
\begin{lstlisting}[language=Python]
E_dvr, psi_dvr = np.linalg.eigh(H_dvr)
E_exact, psi_exact = np.linalg.eigh(H_exact)
S = np.zeros((n_levels, n_levels))
for i in range(n_levels):
    for j in range(n_levels):
        # Calculate the overlap integral
        overlap = np.sum(psi_dvr[:, i].conj() * psi_exact[:, j])
        S[i, j] = np.abs(overlap)
\end{lstlisting}
where \texttt{n\_levels} is the number of energy levels we are interested in. The reader might notice the lack of $\Delta x$ in the overlap integral, this is due to how \texttt{numpy} produces normalized basis sets from diagonalization in the \texttt{eigh} function, so their (discrete) normalization is already accounted for. The overlap matrix $S$ is then a $n_{\text{levels}} \times n_{\text{levels}}$ matrix, where each element $S_{nm}$ represents the overlap between the $n$th Sinc-DVR basis function and the $m$th exact energy eigenstate of the system.

\end{document}